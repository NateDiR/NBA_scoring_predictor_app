{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04a20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/03 21:07:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('GCSFilesRead').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\",\"root-quasar-182016-a55c6c32176d.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name=\"ndir-metis-bucket\"\n",
    "path=f\"gs://{bucket_name}/asteroid/Asteroid_Updated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- a: string (nullable = true)\n",
      " |-- e: string (nullable = true)\n",
      " |-- i: string (nullable = true)\n",
      " |-- om: string (nullable = true)\n",
      " |-- w: string (nullable = true)\n",
      " |-- q: string (nullable = true)\n",
      " |-- ad: string (nullable = true)\n",
      " |-- per_y: string (nullable = true)\n",
      " |-- data_arc: string (nullable = true)\n",
      " |-- condition_code: string (nullable = true)\n",
      " |-- n_obs_used: string (nullable = true)\n",
      " |-- H: string (nullable = true)\n",
      " |-- neo: string (nullable = true)\n",
      " |-- pha: string (nullable = true)\n",
      " |-- diameter: string (nullable = true)\n",
      " |-- extent: string (nullable = true)\n",
      " |-- albedo: string (nullable = true)\n",
      " |-- rot_per: string (nullable = true)\n",
      " |-- GM: string (nullable = true)\n",
      " |-- BV: string (nullable = true)\n",
      " |-- UB: string (nullable = true)\n",
      " |-- IR: string (nullable = true)\n",
      " |-- spec_B: string (nullable = true)\n",
      " |-- spec_T: string (nullable = true)\n",
      " |-- G: string (nullable = true)\n",
      " |-- moid: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- n: string (nullable = true)\n",
      " |-- per: string (nullable = true)\n",
      " |-- ma: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(path, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Info\n",
    "- a: semi-major axis (au)\n",
    "- e: eccentricity\n",
    "- i: inclination with respect to ecliptic plane\n",
    "- om: longitude of the ascending node\n",
    "- w: argument of perihelion\n",
    "- q: perihelion distance (au)\n",
    "- ad: aphelion distance (au)\n",
    "- per_y: orbital period (years)\n",
    "- data_arc: span of recorded data (days)\n",
    "- condition_code: orbital condition code\n",
    "- n_obs_used: number of observations used\n",
    "- H: absolute magnitude parameter\n",
    "- neo: near-earth object\n",
    "- pha: physically hazardous object\n",
    "- diameter: diameter (target variable)\n",
    "- extent: Object bi/tri axial ellipsoid dimensions(Km)\n",
    "- albedo: geometric albedo\n",
    "- rot_per: rotation period (hours)\n",
    "- GM: gravitational parameter. Product of mass and gravitational constant\n",
    "- BV: Color index B-V magnitude difference\n",
    "- UB: Color index U-B magnitude difference\n",
    "- IR: Color index I-R magnitude difference\n",
    "- specB: Spectral taxonomic type(SMASSII)\n",
    "- specT: Spectral taxonomic type (Tholen)\n",
    "- G: Magnitude slope parameter\n",
    "- moid: Earth minimum orbit intersection distance\n",
    "- class: asteroid orbit class\n",
    "- n: mean motion (degrees/day)\n",
    "- per: orbital period (days)\n",
    "- ma: mean ananomly (degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e7caf9a0330a0431ece04fbb5ae0c2702e926a952f28ce7bb1847c9f40f39fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('engineering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
