{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04a20f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/04 17:23:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('GCSFilesRead').config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\",\"root-quasar-182016-a55c6c32176d.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name=\"ndir-metis-bucket\"\n",
    "path=f\"gs://{bucket_name}/asteroid/Asteroid_Updated.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- a: double (nullable = true)\n",
      " |-- e: double (nullable = true)\n",
      " |-- i: double (nullable = true)\n",
      " |-- om: double (nullable = true)\n",
      " |-- w: double (nullable = true)\n",
      " |-- q: double (nullable = true)\n",
      " |-- ad: double (nullable = true)\n",
      " |-- per_y: double (nullable = true)\n",
      " |-- data_arc: integer (nullable = true)\n",
      " |-- condition_code: string (nullable = true)\n",
      " |-- n_obs_used: integer (nullable = true)\n",
      " |-- H: double (nullable = true)\n",
      " |-- neo: string (nullable = true)\n",
      " |-- pha: string (nullable = true)\n",
      " |-- diameter: string (nullable = true)\n",
      " |-- extent: string (nullable = true)\n",
      " |-- albedo: double (nullable = true)\n",
      " |-- rot_per: double (nullable = true)\n",
      " |-- GM: double (nullable = true)\n",
      " |-- BV: double (nullable = true)\n",
      " |-- UB: double (nullable = true)\n",
      " |-- IR: double (nullable = true)\n",
      " |-- spec_B: string (nullable = true)\n",
      " |-- spec_T: string (nullable = true)\n",
      " |-- G: double (nullable = true)\n",
      " |-- moid: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- n: double (nullable = true)\n",
      " |-- per: double (nullable = true)\n",
      " |-- ma: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(path, sep=',', inferSchema=True, header=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Info\n",
    "- a: semi-major axis (au)\n",
    "- e: eccentricity\n",
    "- i: inclination with respect to ecliptic plane\n",
    "- om: longitude of the ascending node\n",
    "- w: argument of perihelion\n",
    "- q: perihelion distance (au)\n",
    "- ad: aphelion distance (au)\n",
    "- per_y: orbital period (years)\n",
    "- data_arc: span of recorded data (days)\n",
    "- condition_code: orbital condition code\n",
    "- n_obs_used: number of observations used\n",
    "- H: absolute magnitude parameter\n",
    "- neo: near-earth object\n",
    "- pha: physically hazardous object\n",
    "- diameter: diameter (target variable)\n",
    "- extent: Object bi/tri axial ellipsoid dimensions(Km)\n",
    "- albedo: geometric albedo\n",
    "- rot_per: rotation period (hours)\n",
    "- GM: gravitational parameter. Product of mass and gravitational constant\n",
    "- BV: Color index B-V magnitude difference\n",
    "- UB: Color index U-B magnitude difference\n",
    "- IR: Color index I-R magnitude difference\n",
    "- specB: Spectral taxonomic type(SMASSII)\n",
    "- specT: Spectral taxonomic type (Tholen)\n",
    "- G: Magnitude slope parameter\n",
    "- moid: Earth minimum orbit intersection distance\n",
    "- class: asteroid orbit class\n",
    "- n: mean motion (degrees/day)\n",
    "- per: orbital period (days)\n",
    "- ma: mean ananomly (degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/04 17:23:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>condition_code</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>diameter</th>\n",
       "      <th>extent</th>\n",
       "      <th>albedo</th>\n",
       "      <th>rot_per</th>\n",
       "      <th>GM</th>\n",
       "      <th>BV</th>\n",
       "      <th>UB</th>\n",
       "      <th>IR</th>\n",
       "      <th>spec_B</th>\n",
       "      <th>spec_T</th>\n",
       "      <th>G</th>\n",
       "      <th>moid</th>\n",
       "      <th>class</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ceres</td>\n",
       "      <td>2.769165</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305532</td>\n",
       "      <td>73.597694</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>8822</td>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>3.34</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>939.4</td>\n",
       "      <td>964.4 x 964.2 x 891.8</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>9.074170</td>\n",
       "      <td>62.6284</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.426</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.594780</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>1683.145708</td>\n",
       "      <td>77.372096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pallas</td>\n",
       "      <td>2.772466</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>34.836234</td>\n",
       "      <td>173.080063</td>\n",
       "      <td>310.048857</td>\n",
       "      <td>2.133865</td>\n",
       "      <td>3.411067</td>\n",
       "      <td>4.616444</td>\n",
       "      <td>72318</td>\n",
       "      <td>0</td>\n",
       "      <td>8490</td>\n",
       "      <td>4.13</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>545</td>\n",
       "      <td>582x556x500</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>7.813200</td>\n",
       "      <td>14.3000</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.284</td>\n",
       "      <td>None</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.233240</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213503</td>\n",
       "      <td>1686.155999</td>\n",
       "      <td>59.699133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Juno</td>\n",
       "      <td>2.669150</td>\n",
       "      <td>0.256942</td>\n",
       "      <td>12.988919</td>\n",
       "      <td>169.852760</td>\n",
       "      <td>248.138626</td>\n",
       "      <td>1.983332</td>\n",
       "      <td>3.354967</td>\n",
       "      <td>4.360814</td>\n",
       "      <td>72684</td>\n",
       "      <td>0</td>\n",
       "      <td>7104</td>\n",
       "      <td>5.33</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>246.596</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>7.210000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.433</td>\n",
       "      <td>None</td>\n",
       "      <td>Sk</td>\n",
       "      <td>S</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.034540</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.226019</td>\n",
       "      <td>1592.787285</td>\n",
       "      <td>34.925016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vesta</td>\n",
       "      <td>2.361418</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>24288</td>\n",
       "      <td>0</td>\n",
       "      <td>9325</td>\n",
       "      <td>3.20</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>525.4</td>\n",
       "      <td>572.6 x 557.2 x 446.4</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>5.342128</td>\n",
       "      <td>17.8000</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.492</td>\n",
       "      <td>None</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.139480</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>1325.432765</td>\n",
       "      <td>95.861936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Astraea</td>\n",
       "      <td>2.574249</td>\n",
       "      <td>0.191095</td>\n",
       "      <td>5.366988</td>\n",
       "      <td>141.576605</td>\n",
       "      <td>358.687607</td>\n",
       "      <td>2.082324</td>\n",
       "      <td>3.066174</td>\n",
       "      <td>4.130323</td>\n",
       "      <td>63507</td>\n",
       "      <td>0</td>\n",
       "      <td>2916</td>\n",
       "      <td>6.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>106.699</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>16.806000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.411</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.095890</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>1508.600458</td>\n",
       "      <td>282.366289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hebe</td>\n",
       "      <td>2.425160</td>\n",
       "      <td>0.203007</td>\n",
       "      <td>14.737901</td>\n",
       "      <td>138.640203</td>\n",
       "      <td>239.807490</td>\n",
       "      <td>1.932835</td>\n",
       "      <td>2.917485</td>\n",
       "      <td>3.776755</td>\n",
       "      <td>62329</td>\n",
       "      <td>0</td>\n",
       "      <td>6034</td>\n",
       "      <td>5.71</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>185.18</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2679</td>\n",
       "      <td>7.274500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.399</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.973965</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.260972</td>\n",
       "      <td>1379.459705</td>\n",
       "      <td>86.197923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iris</td>\n",
       "      <td>2.385334</td>\n",
       "      <td>0.231206</td>\n",
       "      <td>5.523651</td>\n",
       "      <td>259.563231</td>\n",
       "      <td>145.265106</td>\n",
       "      <td>1.833831</td>\n",
       "      <td>2.936837</td>\n",
       "      <td>3.684105</td>\n",
       "      <td>62452</td>\n",
       "      <td>0</td>\n",
       "      <td>5206</td>\n",
       "      <td>5.51</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>199.83</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2766</td>\n",
       "      <td>7.139000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.484</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.267535</td>\n",
       "      <td>1345.619196</td>\n",
       "      <td>140.419656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Flora</td>\n",
       "      <td>2.201764</td>\n",
       "      <td>0.156499</td>\n",
       "      <td>5.886955</td>\n",
       "      <td>110.889330</td>\n",
       "      <td>285.287462</td>\n",
       "      <td>1.857190</td>\n",
       "      <td>2.546339</td>\n",
       "      <td>3.267115</td>\n",
       "      <td>62655</td>\n",
       "      <td>0</td>\n",
       "      <td>2744</td>\n",
       "      <td>6.49</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>147.491</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>12.865000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.489</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.874176</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.301681</td>\n",
       "      <td>1193.313717</td>\n",
       "      <td>194.882895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Metis</td>\n",
       "      <td>2.385637</td>\n",
       "      <td>0.123114</td>\n",
       "      <td>5.576816</td>\n",
       "      <td>68.908577</td>\n",
       "      <td>6.417369</td>\n",
       "      <td>2.091931</td>\n",
       "      <td>2.679342</td>\n",
       "      <td>3.684806</td>\n",
       "      <td>61821</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>6.28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>190</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>5.079000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.496</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.106910</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.267484</td>\n",
       "      <td>1345.875362</td>\n",
       "      <td>276.861623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hygiea</td>\n",
       "      <td>3.141539</td>\n",
       "      <td>0.112461</td>\n",
       "      <td>3.831560</td>\n",
       "      <td>283.202167</td>\n",
       "      <td>312.315206</td>\n",
       "      <td>2.788240</td>\n",
       "      <td>3.494839</td>\n",
       "      <td>5.568291</td>\n",
       "      <td>62175</td>\n",
       "      <td>0</td>\n",
       "      <td>3409</td>\n",
       "      <td>5.43</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>407.12</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>27.630000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.351</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.778390</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.177007</td>\n",
       "      <td>2033.818284</td>\n",
       "      <td>152.184851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Parthenope</td>\n",
       "      <td>2.453109</td>\n",
       "      <td>0.100472</td>\n",
       "      <td>4.629886</td>\n",
       "      <td>125.546585</td>\n",
       "      <td>195.550396</td>\n",
       "      <td>2.206640</td>\n",
       "      <td>2.699579</td>\n",
       "      <td>3.842232</td>\n",
       "      <td>61755</td>\n",
       "      <td>0</td>\n",
       "      <td>5492</td>\n",
       "      <td>6.55</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>142.887</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>13.720400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.417</td>\n",
       "      <td>None</td>\n",
       "      <td>Sk</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.193220</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.256524</td>\n",
       "      <td>1403.375193</td>\n",
       "      <td>278.930692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Victoria</td>\n",
       "      <td>2.334315</td>\n",
       "      <td>0.220172</td>\n",
       "      <td>8.373074</td>\n",
       "      <td>235.410169</td>\n",
       "      <td>69.641819</td>\n",
       "      <td>1.820365</td>\n",
       "      <td>2.848265</td>\n",
       "      <td>3.566543</td>\n",
       "      <td>61769</td>\n",
       "      <td>0</td>\n",
       "      <td>3090</td>\n",
       "      <td>7.24</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>115.087</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>8.659900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.515</td>\n",
       "      <td>None</td>\n",
       "      <td>L</td>\n",
       "      <td>S</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.824953</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.276353</td>\n",
       "      <td>1302.679690</td>\n",
       "      <td>133.335892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Egeria</td>\n",
       "      <td>2.575981</td>\n",
       "      <td>0.085121</td>\n",
       "      <td>16.536125</td>\n",
       "      <td>43.221913</td>\n",
       "      <td>80.544823</td>\n",
       "      <td>2.356710</td>\n",
       "      <td>2.795252</td>\n",
       "      <td>4.134492</td>\n",
       "      <td>61680</td>\n",
       "      <td>0</td>\n",
       "      <td>2385</td>\n",
       "      <td>6.74</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>222.792</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7.045000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.452</td>\n",
       "      <td>None</td>\n",
       "      <td>Ch</td>\n",
       "      <td>G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.436330</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.238391</td>\n",
       "      <td>1510.123380</td>\n",
       "      <td>187.488522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Irene</td>\n",
       "      <td>2.585567</td>\n",
       "      <td>0.166582</td>\n",
       "      <td>9.121646</td>\n",
       "      <td>86.122665</td>\n",
       "      <td>97.858985</td>\n",
       "      <td>2.154858</td>\n",
       "      <td>3.016277</td>\n",
       "      <td>4.157593</td>\n",
       "      <td>61526</td>\n",
       "      <td>0</td>\n",
       "      <td>2755</td>\n",
       "      <td>6.30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>152</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>15.028000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.388</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.179660</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.237067</td>\n",
       "      <td>1518.560847</td>\n",
       "      <td>164.935853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Eunomia</td>\n",
       "      <td>2.644100</td>\n",
       "      <td>0.186084</td>\n",
       "      <td>11.752430</td>\n",
       "      <td>292.934339</td>\n",
       "      <td>98.498681</td>\n",
       "      <td>2.152075</td>\n",
       "      <td>3.136126</td>\n",
       "      <td>4.299571</td>\n",
       "      <td>61247</td>\n",
       "      <td>0</td>\n",
       "      <td>2501</td>\n",
       "      <td>5.28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>231.689</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>6.083000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.451</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.194850</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.229238</td>\n",
       "      <td>1570.418187</td>\n",
       "      <td>283.387698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Psyche</td>\n",
       "      <td>2.923814</td>\n",
       "      <td>0.133568</td>\n",
       "      <td>3.096005</td>\n",
       "      <td>150.045666</td>\n",
       "      <td>228.823071</td>\n",
       "      <td>2.533285</td>\n",
       "      <td>3.314343</td>\n",
       "      <td>4.999571</td>\n",
       "      <td>12856</td>\n",
       "      <td>0</td>\n",
       "      <td>2364</td>\n",
       "      <td>5.90</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>226</td>\n",
       "      <td>279 x 232 x 189</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>4.196000</td>\n",
       "      <td>1.5300</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.299</td>\n",
       "      <td>None</td>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.535800</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.197142</td>\n",
       "      <td>1826.093319</td>\n",
       "      <td>288.335893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thetis</td>\n",
       "      <td>2.470354</td>\n",
       "      <td>0.133032</td>\n",
       "      <td>5.591205</td>\n",
       "      <td>125.552945</td>\n",
       "      <td>136.208250</td>\n",
       "      <td>2.141719</td>\n",
       "      <td>2.798989</td>\n",
       "      <td>3.882818</td>\n",
       "      <td>61117</td>\n",
       "      <td>0</td>\n",
       "      <td>3666</td>\n",
       "      <td>7.76</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>84.899</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>12.270480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.438</td>\n",
       "      <td>None</td>\n",
       "      <td>Sl</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.129810</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.253843</td>\n",
       "      <td>1418.199204</td>\n",
       "      <td>303.364363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Melpomene</td>\n",
       "      <td>2.296654</td>\n",
       "      <td>0.217674</td>\n",
       "      <td>10.128731</td>\n",
       "      <td>150.383862</td>\n",
       "      <td>227.950847</td>\n",
       "      <td>1.796731</td>\n",
       "      <td>2.796576</td>\n",
       "      <td>3.480578</td>\n",
       "      <td>60906</td>\n",
       "      <td>0</td>\n",
       "      <td>5082</td>\n",
       "      <td>6.51</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>139.594</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1810</td>\n",
       "      <td>11.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.425</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.813258</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.283179</td>\n",
       "      <td>1271.281262</td>\n",
       "      <td>267.254381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fortuna</td>\n",
       "      <td>2.442711</td>\n",
       "      <td>0.158047</td>\n",
       "      <td>1.573782</td>\n",
       "      <td>211.144044</td>\n",
       "      <td>182.065018</td>\n",
       "      <td>2.056648</td>\n",
       "      <td>2.828773</td>\n",
       "      <td>3.817827</td>\n",
       "      <td>60970</td>\n",
       "      <td>0</td>\n",
       "      <td>3316</td>\n",
       "      <td>7.13</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>7.443200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.324</td>\n",
       "      <td>None</td>\n",
       "      <td>Ch</td>\n",
       "      <td>G</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.062130</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.258164</td>\n",
       "      <td>1394.461340</td>\n",
       "      <td>197.338626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Massalia</td>\n",
       "      <td>2.409782</td>\n",
       "      <td>0.142067</td>\n",
       "      <td>0.708751</td>\n",
       "      <td>206.108911</td>\n",
       "      <td>256.773196</td>\n",
       "      <td>2.067432</td>\n",
       "      <td>2.752132</td>\n",
       "      <td>3.740889</td>\n",
       "      <td>59461</td>\n",
       "      <td>0</td>\n",
       "      <td>2481</td>\n",
       "      <td>6.50</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>135.680</td>\n",
       "      <td>None</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>8.098000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.463</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>S</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.084610</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.263474</td>\n",
       "      <td>1366.359575</td>\n",
       "      <td>117.695129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name         a         e          i          om           w  \\\n",
       "0        Ceres  2.769165  0.076009  10.594067   80.305532   73.597694   \n",
       "1       Pallas  2.772466  0.230337  34.836234  173.080063  310.048857   \n",
       "2         Juno  2.669150  0.256942  12.988919  169.852760  248.138626   \n",
       "3        Vesta  2.361418  0.088721   7.141771  103.810804  150.728541   \n",
       "4      Astraea  2.574249  0.191095   5.366988  141.576605  358.687607   \n",
       "5         Hebe  2.425160  0.203007  14.737901  138.640203  239.807490   \n",
       "6         Iris  2.385334  0.231206   5.523651  259.563231  145.265106   \n",
       "7        Flora  2.201764  0.156499   5.886955  110.889330  285.287462   \n",
       "8        Metis  2.385637  0.123114   5.576816   68.908577    6.417369   \n",
       "9       Hygiea  3.141539  0.112461   3.831560  283.202167  312.315206   \n",
       "10  Parthenope  2.453109  0.100472   4.629886  125.546585  195.550396   \n",
       "11    Victoria  2.334315  0.220172   8.373074  235.410169   69.641819   \n",
       "12      Egeria  2.575981  0.085121  16.536125   43.221913   80.544823   \n",
       "13       Irene  2.585567  0.166582   9.121646   86.122665   97.858985   \n",
       "14     Eunomia  2.644100  0.186084  11.752430  292.934339   98.498681   \n",
       "15      Psyche  2.923814  0.133568   3.096005  150.045666  228.823071   \n",
       "16      Thetis  2.470354  0.133032   5.591205  125.552945  136.208250   \n",
       "17   Melpomene  2.296654  0.217674  10.128731  150.383862  227.950847   \n",
       "18     Fortuna  2.442711  0.158047   1.573782  211.144044  182.065018   \n",
       "19    Massalia  2.409782  0.142067   0.708751  206.108911  256.773196   \n",
       "\n",
       "           q        ad     per_y  data_arc condition_code  n_obs_used     H  \\\n",
       "0   2.558684  2.979647  4.608202      8822              0        1002  3.34   \n",
       "1   2.133865  3.411067  4.616444     72318              0        8490  4.13   \n",
       "2   1.983332  3.354967  4.360814     72684              0        7104  5.33   \n",
       "3   2.151909  2.570926  3.628837     24288              0        9325  3.20   \n",
       "4   2.082324  3.066174  4.130323     63507              0        2916  6.85   \n",
       "5   1.932835  2.917485  3.776755     62329              0        6034  5.71   \n",
       "6   1.833831  2.936837  3.684105     62452              0        5206  5.51   \n",
       "7   1.857190  2.546339  3.267115     62655              0        2744  6.49   \n",
       "8   2.091931  2.679342  3.684806     61821              0        2649  6.28   \n",
       "9   2.788240  3.494839  5.568291     62175              0        3409  5.43   \n",
       "10  2.206640  2.699579  3.842232     61755              0        5492  6.55   \n",
       "11  1.820365  2.848265  3.566543     61769              0        3090  7.24   \n",
       "12  2.356710  2.795252  4.134492     61680              0        2385  6.74   \n",
       "13  2.154858  3.016277  4.157593     61526              0        2755  6.30   \n",
       "14  2.152075  3.136126  4.299571     61247              0        2501  5.28   \n",
       "15  2.533285  3.314343  4.999571     12856              0        2364  5.90   \n",
       "16  2.141719  2.798989  3.882818     61117              0        3666  7.76   \n",
       "17  1.796731  2.796576  3.480578     60906              0        5082  6.51   \n",
       "18  2.056648  2.828773  3.817827     60970              0        3316  7.13   \n",
       "19  2.067432  2.752132  3.740889     59461              0        2481  6.50   \n",
       "\n",
       "   neo pha diameter                 extent  albedo    rot_per       GM     BV  \\\n",
       "0    N   N    939.4  964.4 x 964.2 x 891.8  0.0900   9.074170  62.6284  0.713   \n",
       "1    N   N      545            582x556x500  0.1010   7.813200  14.3000  0.635   \n",
       "2    N   N  246.596                   None  0.2140   7.210000      NaN  0.824   \n",
       "3    N   N    525.4  572.6 x 557.2 x 446.4  0.4228   5.342128  17.8000  0.782   \n",
       "4    N   N  106.699                   None  0.2740  16.806000      NaN  0.826   \n",
       "5    N   N   185.18                   None  0.2679   7.274500      NaN  0.822   \n",
       "6    N   N   199.83                   None  0.2766   7.139000      NaN  0.855   \n",
       "7    N   N  147.491                   None  0.2260  12.865000      NaN  0.885   \n",
       "8    N   N      190                   None  0.1180   5.079000      NaN  0.858   \n",
       "9    N   N   407.12                   None  0.0717  27.630000   7.0000  0.696   \n",
       "10   N   N  142.887                   None  0.1910  13.720400      NaN  0.837   \n",
       "11   N   N  115.087                   None  0.1630   8.659900      NaN  0.874   \n",
       "12   N   N  222.792                   None  0.0700   7.045000      NaN  0.745   \n",
       "13   N   N      152                   None  0.1590  15.028000      NaN  0.833   \n",
       "14   N   N  231.689                   None  0.2480   6.083000      NaN  0.839   \n",
       "15   N   N     226         279 x 232 x 189  0.1203   4.196000   1.5300  0.729   \n",
       "16   N   N   84.899                   None  0.1930  12.270480      NaN  0.829   \n",
       "17   N   N  139.594                   None  0.1810  11.570000      NaN  0.854   \n",
       "18   N   N      200                   None  0.0370   7.443200      NaN  0.719   \n",
       "19   N   N  135.680                   None  0.2410   8.098000      NaN  0.854   \n",
       "\n",
       "       UB    IR spec_B spec_T     G      moid class         n          per  \\\n",
       "0   0.426  None      C      G  0.12  1.594780   MBA  0.213885  1683.145708   \n",
       "1   0.284  None      B      B  0.11  1.233240   MBA  0.213503  1686.155999   \n",
       "2   0.433  None     Sk      S  0.32  1.034540   MBA  0.226019  1592.787285   \n",
       "3   0.492  None      V      V  0.32  1.139480   MBA  0.271609  1325.432765   \n",
       "4   0.411  None      S      S   NaN  1.095890   MBA  0.238632  1508.600458   \n",
       "5   0.399  None      S      S  0.24  0.973965   MBA  0.260972  1379.459705   \n",
       "6   0.484  None      S      S   NaN  0.846100   MBA  0.267535  1345.619196   \n",
       "7   0.489  None   None      S  0.28  0.874176   MBA  0.301681  1193.313717   \n",
       "8   0.496  None   None      S  0.17  1.106910   MBA  0.267484  1345.875362   \n",
       "9   0.351  None      C      C   NaN  1.778390   MBA  0.177007  2033.818284   \n",
       "10  0.417  None     Sk      S   NaN  1.193220   MBA  0.256524  1403.375193   \n",
       "11  0.515  None      L      S  0.22  0.824953   MBA  0.276353  1302.679690   \n",
       "12  0.452  None     Ch      G   NaN  1.436330   MBA  0.238391  1510.123380   \n",
       "13  0.388  None      S      S   NaN  1.179660   MBA  0.237067  1518.560847   \n",
       "14  0.451  None      S      S  0.23  1.194850   MBA  0.229238  1570.418187   \n",
       "15  0.299  None      X      M  0.20  1.535800   MBA  0.197142  1826.093319   \n",
       "16  0.438  None     Sl      S   NaN  1.129810   MBA  0.253843  1418.199204   \n",
       "17  0.425  None      S      S  0.25  0.813258   MBA  0.283179  1271.281262   \n",
       "18  0.324  None     Ch      G  0.10  1.062130   MBA  0.258164  1394.461340   \n",
       "19  0.463  None      S      S  0.25  1.084610   MBA  0.263474  1366.359575   \n",
       "\n",
       "            ma  \n",
       "0    77.372096  \n",
       "1    59.699133  \n",
       "2    34.925016  \n",
       "3    95.861936  \n",
       "4   282.366289  \n",
       "5    86.197923  \n",
       "6   140.419656  \n",
       "7   194.882895  \n",
       "8   276.861623  \n",
       "9   152.184851  \n",
       "10  278.930692  \n",
       "11  133.335892  \n",
       "12  187.488522  \n",
       "13  164.935853  \n",
       "14  283.387698  \n",
       "15  288.335893  \n",
       "16  303.364363  \n",
       "17  267.254381  \n",
       "18  197.338626  \n",
       "19  117.695129  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preview(df, n=20):\n",
    "    return pd.DataFrame(df.take(n), columns=df.columns)\n",
    "preview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = df.dropna(subset=['diameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.drop('extent', 'rot_per', 'GM', 'BV', 'UB', 'IR', 'spec_B', 'spec_T', 'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.drop('name', 'data_arc', 'H', 'albedo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(string):\n",
    "    return (string\n",
    "    .replace('Y', 'True')\n",
    "    .replace('N', 'False')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = udf(trim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dtype in astro_df.dtypes:\n",
    "    column = dtype[0]\n",
    "    if dtype[1] == 'string':\n",
    "        astro_df = astro_df.withColumn(column, trim(astro_df[column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.withColumn('diameter', astro_df['diameter'].cast('integer').cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.withColumn('n_obs_used', astro_df['n_obs_used'].cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['neo', 'pha']:\n",
    "    astro_df = astro_df.withColumn(column, astro_df[column].cast('boolean').cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_code_indexer = StringIndexer(inputCol=\"condition_code\", outputCol=\"condition_codeIndex\")\n",
    "class_indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n",
    "onehotencoder_condition_code_vector = OneHotEncoder(inputCol=\"condition_codeIndex\", outputCol=\"condition_code_vec\")\n",
    "onehotencoder_class_vector = OneHotEncoder(inputCol=\"classIndex\", outputCol=\"class_vec\")\n",
    "\n",
    "#Create pipeline and pass all stages\n",
    "encoding_pipeline = Pipeline(stages=[condition_code_indexer,\n",
    "                            class_indexer,\n",
    "                            onehotencoder_condition_code_vector,\n",
    "                            onehotencoder_class_vector\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "astro_df = encoding_pipeline.fit(astro_df).transform(astro_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.drop('condition_code', 'class', 'condition_codeIndex', 'classIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_df = astro_df.select(\"a\",\"e\",\"i\",'om','w','q','ad', 'per_y', 'n_obs_used', 'neo', 'pha', 'moid', 'n', 'per', 'ma', 'condition_code_vec', 'class_vec', 'diameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = astro_df.randomSplit([0.6, 0.2, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'e',\n",
       " 'i',\n",
       " 'om',\n",
       " 'w',\n",
       " 'q',\n",
       " 'ad',\n",
       " 'per_y',\n",
       " 'n_obs_used',\n",
       " 'neo',\n",
       " 'pha',\n",
       " 'moid',\n",
       " 'n',\n",
       " 'per',\n",
       " 'ma',\n",
       " 'condition_code_vec',\n",
       " 'class_vec']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = astro_df.schema.names[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pack = assembler.transform(train_df)\n",
    "val_pack = assembler.transform(val_df)\n",
    "test_pack = assembler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in features:\n",
    "    train_pack = train_pack.drop(field)\n",
    "    val_pack = val_pack.drop(field)\n",
    "    test_pack  = test_pack.drop(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- diameter: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pack.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol='features', labelCol='diameter', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt_model = gbt.fit(train_pack)\n",
    "val_pred = gbt_model.transform(val_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = val_pred.select('prediction', 'diameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- diameter: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_pred.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/04 17:27:20 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/04/04 17:27:20 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/04/04 17:27:24 ERROR Executor: Exception in task 0.0 in stage 113.0 (TID 853)\n",
      "scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n",
      "\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n",
      "\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n",
      "\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n",
      "\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n",
      "\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "22/04/04 17:27:24 WARN TaskSetManager: Lost task 0.0 in stage 113.0 (TID 853) (nathaniels-mbp.lan executor driver): scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n",
      "\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n",
      "\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n",
      "\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n",
      "\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n",
      "\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n",
      "\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "22/04/04 17:27:24 ERROR TaskSetManager: Task 0 in stage 113.0 failed 1 times; aborting job\n",
      "Traceback (most recent call last):                                  (3 + 4) / 8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 663, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 663, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "EOFError\n",
      "22/04/04 17:27:24 WARN TaskSetManager: Lost task 3.0 in stage 113.0 (TID 856) (nathaniels-mbp.lan executor driver): TaskKilled (Stage cancelled)\n",
      "22/04/04 17:27:24 WARN TaskSetManager: Lost task 4.0 in stage 113.0 (TID 857) (nathaniels-mbp.lan executor driver): TaskKilled (Stage cancelled)\n",
      "22/04/04 17:27:24 WARN TaskSetManager: Lost task 2.0 in stage 113.0 (TID 855) (nathaniels-mbp.lan executor driver): TaskKilled (Stage cancelled)\n",
      "22/04/04 17:27:24 WARN TaskSetManager: Lost task 6.0 in stage 113.0 (TID 859) (nathaniels-mbp.lan executor driver): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o572.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 113.0 failed 1 times, most recent failure: Lost task 0.0 in stage 113.0 (TID 853) (nathaniels-mbp.lan executor driver): scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2309)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1183)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1177)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1246)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\n\tat org.apache.spark.mllib.stat.Statistics$.colStats(Statistics.scala:58)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary$lzycompute(RegressionMetrics.scala:70)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary(RegressionMetrics.scala:62)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr$lzycompute(RegressionMetrics.scala:74)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr(RegressionMetrics.scala:74)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.meanSquaredError(RegressionMetrics.scala:106)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.rootMeanSquaredError(RegressionMetrics.scala:115)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:101)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/nathanieldirenzo/Documents/GitHub/celestial_body_size_predictor/asteroid_size_predictor.ipynb Cell 32'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nathanieldirenzo/Documents/GitHub/celestial_body_size_predictor/asteroid_size_predictor.ipynb#ch0000050?line=0'>1</a>\u001b[0m evaluator \u001b[39m=\u001b[39m RegressionEvaluator(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nathanieldirenzo/Documents/GitHub/celestial_body_size_predictor/asteroid_size_predictor.ipynb#ch0000050?line=1'>2</a>\u001b[0m     labelCol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdiameter\u001b[39m\u001b[39m\"\u001b[39m, predictionCol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m, metricName\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nathanieldirenzo/Documents/GitHub/celestial_body_size_predictor/asteroid_size_predictor.ipynb#ch0000050?line=2'>3</a>\u001b[0m rmse \u001b[39m=\u001b[39m evaluator\u001b[39m.\u001b[39;49mevaluate(val_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nathanieldirenzo/Documents/GitHub/celestial_body_size_predictor/asteroid_size_predictor.ipynb#ch0000050?line=3'>4</a>\u001b[0m rmse\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py:84\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=81'>82</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m     <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=82'>83</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=83'>84</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate(dataset)\n\u001b[1;32m     <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=84'>85</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=85'>86</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py:120\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=105'>106</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=106'>107</a>\u001b[0m \u001b[39mEvaluates the output.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=107'>108</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=116'>117</a>\u001b[0m \u001b[39m    evaluation metric\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=117'>118</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=118'>119</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/ml/evaluation.py?line=119'>120</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mevaluate(dataset\u001b[39m.\u001b[39;49m_jdf)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/java_gateway.py?line=1324'>1325</a>\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py?line=108'>109</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py?line=109'>110</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py?line=110'>111</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py?line=111'>112</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m py4j\u001b[39m.\u001b[39mprotocol\u001b[39m.\u001b[39mPy4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/pyspark/sql/utils.py?line=112'>113</a>\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=323'>324</a>\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=324'>325</a>\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=325'>326</a>\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=326'>327</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=327'>328</a>\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=328'>329</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=329'>330</a>\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=330'>331</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    <a href='file:///Users/nathanieldirenzo/opt/anaconda3/envs/engineering/lib/python3.8/site-packages/py4j/protocol.py?line=331'>332</a>\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o572.evaluate.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 113.0 failed 1 times, most recent failure: Lost task 0.0 in stage 113.0 (TID 853) (nathaniels-mbp.lan executor driver): scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2309)\n\tat org.apache.spark.rdd.RDD.$anonfun$fold$1(RDD.scala:1183)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.fold(RDD.scala:1177)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$1(RDD.scala:1246)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1222)\n\tat org.apache.spark.mllib.stat.Statistics$.colStats(Statistics.scala:58)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary$lzycompute(RegressionMetrics.scala:70)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.summary(RegressionMetrics.scala:62)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr$lzycompute(RegressionMetrics.scala:74)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.SSerr(RegressionMetrics.scala:74)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.meanSquaredError(RegressionMetrics.scala:106)\n\tat org.apache.spark.mllib.evaluation.RegressionMetrics.rootMeanSquaredError(RegressionMetrics.scala:115)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.evaluate(RegressionEvaluator.scala:101)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: scala.MatchError: [29.342053008836395,null,1.0] (of class org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema)\n\tat org.apache.spark.ml.evaluation.RegressionEvaluator.$anonfun$getMetrics$1(RegressionEvaluator.scala:127)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:199)\n\tat scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:192)\n\tat scala.collection.AbstractIterator.foldLeft(Iterator.scala:1431)\n\tat scala.collection.TraversableOnce.aggregate(TraversableOnce.scala:260)\n\tat scala.collection.TraversableOnce.aggregate$(TraversableOnce.scala:260)\n\tat scala.collection.AbstractIterator.aggregate(Iterator.scala:1431)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$3(RDD.scala:1230)\n\tat org.apache.spark.rdd.RDD.$anonfun$treeAggregate$5(RDD.scala:1231)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2(RDD.scala:863)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitions$2$adapted(RDD.scala:863)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"diameter\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(val_pred)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e7caf9a0330a0431ece04fbb5ae0c2702e926a952f28ce7bb1847c9f40f39fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('engineering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
